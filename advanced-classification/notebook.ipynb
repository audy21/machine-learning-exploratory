{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36c0f314-1107-48fd-a94c-8eac60f27287",
   "metadata": {},
   "source": [
    "## **Advanced Classification using Machine Learning in HealthCare**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e90615-0a72-4658-bfbf-1970cda64ca3",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "X-rays are widely used in medical practice. They can be used to identify various diseases. However, a diagnosis depends on a doctor's experience, which can lead to improper treatment. Modern methods of artificial intelligence and pattern recognition make it possible to create expert systems that allow you to establish a diagnosis automatically.\n",
    "\n",
    "This lab will show you how to upload images, transform them, and determine the basic features that underlie diseases classification.\n",
    "\n",
    "Two different approaches to the classification of images (diseases) will be shown:\n",
    "1. Different classical methods and their comparison \n",
    "2. Convolutional Neural Networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4c96bd-793d-4d9b-a945-7c7a324642bc",
   "metadata": {},
   "source": [
    "## Materials and methods\n",
    "\n",
    "In this lab, we will learn the basic methods of images classifications. The laboratory consists of four stages:\n",
    "* Download and preliminary transformation of images\n",
    "* Creating image features\n",
    "* Comparing different classical classification methods\n",
    "* Building and fitting Convolutional Neural Network\n",
    "\n",
    "The statistical data was obtained from https://www.kaggle.com/pranavraikokte/covid19-image-dataset under [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/) license."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47794b1-f769-4155-9327-a05edcdc5227",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "* [Python](https://www.python.org)\n",
    "* [os](https://docs.python.org/3/library/os.html)\n",
    "* [numpy](https://numpy.org)\n",
    "* [glob](https://docs.python.org/3/library/glob.html)\n",
    "* [SeaBorn](https://seaborn.pydata.org)\n",
    "* [Matplotlib](https://matplotlib.org)\n",
    "* [mahotas](https://mahotas.readthedocs.io/en/latest/)\n",
    "* [keras](https://keras.io)\n",
    "* [scikit-learn](https://scikit-learn.org)\n",
    "* [pandas](https://pandas.pydata.org)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea661f61-5854-469a-81e0-b083000bd7c9",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "* Download and transform images.\n",
    "* Create features of images.\n",
    "* Build different classification models.\n",
    "* Build CNN models.\n",
    "* Build a diagnosis based on X-ray photos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006c3eb3-1519-46c2-988a-37bcc1d226dd",
   "metadata": {},
   "source": [
    "# Download and preliminary transformation of images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58017e3a-fece-4235-b506-6fee86d1d6b3",
   "metadata": {},
   "source": [
    "## Required libraries installation\n",
    "\n",
    "We need to install additional libraries and upgrade existing ones in the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a19e48-1425-415c-bded-599e1995bead",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mahotas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361045c3-6ca1-459c-b5b9-28d8ed2d9e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e57c6ff-0428-4309-ad6e-385c409d5e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c conda-forge tensorflow --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da8d5c6-afd8-4890-9400-130209067b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c conda-forge keras --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97e4c27-c9f3-49ce-bfe0-f7f33d0f5d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda config --add channels defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb7bb82-0d82-4763-a729-fe03c12f2ab5",
   "metadata": {},
   "source": [
    "## Required libraries import\n",
    "\n",
    "Here we are going to use Mahotas for image processing and Keras library for creating our CNN model and its training. We will also use Matplotlib and Seaborn for visualizing our dataset to gain a better understanding of the images we are going to handle.\n",
    "We will also use libraries os and glob to work with files and folders. NumPy will be applied for arrays of images. Scikit-Learn will be used for classical classification models. And we will take Pandas for present comparison of classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc539c5-6cad-453f-9cca-542f4ff64582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mahotas as mh\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt \n",
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "#Classifiers\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2608770-b232-4e3c-94e5-a422cfaf8a71",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c92900-938d-4c86-92ff-0955f0139a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skillsnetwork\n",
    "\n",
    "await skillsnetwork.prepare(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/data-science-in-health-care-advanced-machine-learning-classification/LargeData/Covid19-dataset.zip\", overwrite=True)\n",
    "await skillsnetwork.prepare(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/data-science-in-health-care-advanced-machine-learning-classification/NN.zip\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9b339d-354d-45d6-a9ad-908aee1d06f1",
   "metadata": {},
   "source": [
    "Images have to be of the same size for classification. In order to achieve this, let's create a global variable that will determine the size (height and width) for image resizing. Both are 224 in our case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9533abd-e091-486c-9d9b-22ffe8d30adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMM_SIZE = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25831836-2ac9-4930-b5c8-2d6e55659458",
   "metadata": {},
   "source": [
    "For convenience, we create a function that downloads and displays all the pictures from a specified directory.\n",
    "In order to classify images, all pictures should be placed in subdirectories. The names of these subdirectories are actually class names.\n",
    "In our case, the images are X-rays which should be placed into subfolders with the names of diagnoses.\n",
    "For example, a COVID subfolder is to contain X-rays of people with this disease.\n",
    "First of all, we should create a list of subfolders, which is a list of possible disease classes. In our case, it will be: Normal, COVID, Viral Pneumonia.\n",
    "\n",
    "Next, we need to create a list of all images.\n",
    "After that, let's download and preprocess all the images:\n",
    "1. Download by [mahotas.imread()](https://mahotas.readthedocs.io/en/latest/io.html)\n",
    "2. It is necessary to resize the images to (IMM_SIZE x IMM_SIZE). If an image is gray-colored it is presented as a 2D matrix: (high, width). jpg and png images are 3D (high, width, 3 or 4). To do this, we should use: [mahotas.resize_to()](https://github.com/luispedro/mahotas/blob/master/mahotas/resize.py)\n",
    "3. If the third parameter of an image shape equals 4, it means alpha channel. We can remove it using slice image[:,:,:3].\n",
    "4. Then we need to transform all the images to gray 2D format by: [mahotas.colors.rgb2grey()](https://mahotas.readthedocs.io/en/latest/color.html)\n",
    "\n",
    "The function returns an array of tuples [image, class name].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11213466-1c3b-41ba-8362-4b7eb18e9994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(folder):\n",
    "    \n",
    "    class_names = [f for f in os.listdir(folder) if not f.startswith('.')] # create a list of SubFolders\n",
    "    images_data = []\n",
    "    labels = []\n",
    "    class_names = ['Covid', 'Normal', 'Viral Pneumonia']\n",
    "    print(class_names)\n",
    "    for t, f in enumerate(class_names):\n",
    "        images = glob(folder + \"/\" + f + \"/*\") # create a list of files\n",
    "        print(\"Downloading: \", f)\n",
    "        fig = plt.figure(figsize = (50,50)) \n",
    "        for im_n, im in enumerate(images):\n",
    "            plt.gray() # set grey colormap of images\n",
    "            image = mh.imread(im)\n",
    "            if len(image.shape) > 2:\n",
    "                image = mh.resize_to(image, [IMM_SIZE, IMM_SIZE, image.shape[2]]) # resize of RGB and png images\n",
    "            else:\n",
    "                image = mh.resize_to(image, [IMM_SIZE, IMM_SIZE]) # resize of grey images    \n",
    "            if len(image.shape) > 2:\n",
    "                image = mh.colors.rgb2grey(image[:,:,:3], dtype = np.uint8)  # change of colormap of images alpha chanel delete\n",
    "            plt.subplot(int(len(images)/5)+1,5,im_n+1) # create a table of images\n",
    "            plt.imshow(image)\n",
    "            images_data.append(image)\n",
    "            labels.append(f)\n",
    "        plt.show()\n",
    "\n",
    "    # Convert images to numpy array after ensuring all have same shape\n",
    "    return np.array(images_data), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b09f96-8492-4432-95cf-5434877ca4d1",
   "metadata": {},
   "source": [
    "For training and testing, all the pictures should be divided into training and test groups and located in separate folders. Let's upload all the images to the corresponding arrays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f38a6b-064b-4128-8dd0-27c498cb7889",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = \"Covid19-dataset/train\"\n",
    "train_images, train_labels = get_data(d)\n",
    "\n",
    "d = \"Covid19-dataset/test\"\n",
    "val_images, val_labels = get_data(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7251aa-d9bd-4b27-9c13-c3b829113552",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train images shape:\", train_images.shape) # Size of the training DataSet\n",
    "print(\"Train labels shape:\", train_labels.shape) # Size of the training labels\n",
    "print(\"Test images shape:\", val_images.shape) # Size of the test DataSet\n",
    "print(\"Test labels shape:\", val_labels.shape) # Size of the test labels\n",
    "print(\"Image size:\", train_images[0].shape) # Size of a single image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ff6785-1071-47dc-a2ca-4884b90def2d",
   "metadata": {},
   "source": [
    "As you can see, the training DataSet consists of 251 images and the test one consists of 66 images. All the images are in grey 2D (224x224) format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b5f245-d71a-4e29-8a52-9ee0ddddfc2f",
   "metadata": {},
   "source": [
    "## Data visualization \n",
    "\n",
    "Let’s visualize our data and see what exactly we are working with. We use Seaborn to plot the number of images in all the classes. You can see what the output looks like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adee6c6-83b6-485c-8997-0d6eb221e1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = train_labels\n",
    "sns.set_style('darkgrid')\n",
    "sns.countplot(l)\n",
    "plt.title('Distribution of Classes in Training Data')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95405d3-ef8e-420e-b672-8fe23c30b609",
   "metadata": {},
   "source": [
    "Let us also visualize the first image from the Viral Pneumonia and Covid classes in the training DataSet:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d733f9-5eb5-4e0f-b5e3-dc3bc2282500",
   "metadata": {},
   "outputs": [],
   "source": [
    "viral_pneumonia_indices = np.where(train_labels == 'Viral Pneumonia')[0]\n",
    "\n",
    "\n",
    "plt.figure(figsize = (5,5))\n",
    "plt.imshow(train_images[viral_pneumonia_indices[0]])\n",
    "plt.title('Viral Pneumonia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aa9fcd-8a42-4128-9799-caccfb498e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_indices = np.where(train_labels == 'Covid')[0]\n",
    "\n",
    "plt.figure(figsize = (5,5))\n",
    "plt.imshow(train_images[covid_indices[0]])\n",
    "plt.title('Covid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c778b0d-9e45-480e-bb30-bb93a51d4e44",
   "metadata": {},
   "source": [
    "## Image features creation\n",
    "\n",
    "To classify objects, you need to transform the data set so that the input is a set of features and the output is an object class. An image is a matrix of pixels. Each pixel is a color. Therefore, it is impossible to submit a bare picture into a classical classifier's input. It is necessary to turn each picture into a set of certain features.\n",
    "\n",
    "Mahotas makes it easy to calculate features of an image.\n",
    "The corresponding functions are found in the [mahotas.features](https://mahotas.readthedocs.io/en/latest/) submodule. The Haralick set of texture features is well known. Like many image processing algorithms, it is named for its inventor. The features are based on textures, that is, they distinguish between structured and unstructured images, as well as various repetitive structures. With the help of Mahotas, these features are calculated very easily:\n",
    "haralick_features = mh.features.haralick (image)\n",
    "haralick_features_mean = np.mean (haralick_features, axis = O)\n",
    "haralick_features_all = np.ravel (haralick_features)\n",
    "The mh.features.haralick function returns a 4 x 13 array wiсh should be transformad into 1D by [NumPy.ravel()](https://numpy.org/doc/stable/reference/generated/numpy.ravel.html). The first dimension is the four possible directions in which the features are calculated (vertical, horizontal, and two diagonals). If we are not interested in any particular direction, then we can average the features in all directions (in the code above, this variable is called haralick_features_mean). Alternatively, you can use all the characteristics individually (variable haralick_features_all). The choice depends on the properties of a particular dataset. We decided that the vertical and horizontal features should be stored separately in our case, so we use haralick_features_all.\n",
    "\n",
    "We should make a function for the DataSet features creation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da184fbb-0b0c-4185-9c01-8eff3b487929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(images, labels):\n",
    "    features = []\n",
    "    for image in images:\n",
    "        features.append(mh.features.haralick(image).ravel())\n",
    "    features = np.array(features)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844f3945-ce2e-454f-8082-380d27541a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, labels_train = create_features(train_images, train_labels)\n",
    "features_test, labels_test = create_features(val_images, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d116740-59ee-4498-8e7f-81a91e685a87",
   "metadata": {},
   "source": [
    "# Comparing different classical classification methods\n",
    "\n",
    "If we want to compare some classificators, we should use a Pipeline.\n",
    "A pipeline helps to chain multiple estimators into a single one. This is useful as there is often a fixed number of steps in data processing, for example, feature selection, normalization and classification. A pipeline serves multiple purposes here:\n",
    "\n",
    "You only have to call fit() once to evaluate a whole sequence of estimators.\n",
    "\n",
    "You can grid search over parameters of all estimators in the pipeline at once.\n",
    "\n",
    "Pipelines help to avoid leaking statistics from your test data into the trained model in cross-validation by ensuring that the same samples are used to train the transformers and predictors.\n",
    "All estimators in a pipeline, except the last one, should be transformers (i.e. should have a transform method). The last estimator may be of any type (transformer, classifier, etc.).\n",
    "\n",
    "The [sklearn.pipeline](https://scikit-learn.org/stable/modules/classes.html?highlight=pipeline#module-sklearn.pipeline) module implements utilities to build a composite estimator, as a chain of transforms and estimators.\n",
    "\n",
    "In order to test how it works, we will use LogisticRegression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fafde1-bd4b-416c-8502-cd80aba1bbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([('preproc', StandardScaler()), ('classifier', LogisticRegression())])\n",
    "clf.fit(features_train, labels_train)\n",
    "scores_train = clf.score(features_train, labels_train)\n",
    "scores_test = clf.score(features_test, labels_test)\n",
    "print('Training DataSet accuracy: {: .1%}'.format(scores_train), 'Test DataSet accuracy: {: .1%}'.format(scores_test))\n",
    "ConfusionMatrixDisplay.from_estimator(clf, features_test, labels_test)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acab3f7f-f1e2-4336-9f0c-b4b7eec29edf",
   "metadata": {},
   "source": [
    "As you can see, the results are not bad.\n",
    "Conflusion matrix shows us how many mistaken predictions we got.\n",
    "It allows us to check other classifiers and compare the results.\n",
    "We will test:\n",
    "* [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regression#sklearn.linear_model.LogisticRegression)\n",
    "* [Nearest Neighbors](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html?highlight=nearest%20neighbors#sklearn.neighbors.NearestNeighbors)\n",
    "* [Linear SVM](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVR.html?highlight=linear%20svm#sklearn.svm.LinearSVR)\n",
    "* [RBF SVM](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.RBF.html?highlight=rbf#sklearn.gaussian_process.kernels.RBF)\n",
    "* [Gaussian Process](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessClassifier.html?highlight=gaussianprocessclassifier#sklearn.gaussian_process.GaussianProcessClassifier)\n",
    "* [Decision Tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html?highlight=decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier)\n",
    "* [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html?highlight=randomforestclassifier#sklearn.ensemble.RandomForestClassifier)\n",
    "* [Multi-layer Perceptron classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html?highlight=mlpclassifier#sklearn.neural_network.MLPClassifier)\n",
    "* [Ada Boost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html?highlight=adaboostclassifier#sklearn.ensemble.AdaBoostClassifier)\n",
    "* [Naive Bayes](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html?highlight=gaussiannb#sklearn.naive_bayes.GaussianNB)\n",
    "* [Quadratic Discriminant Analysis](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html?highlight=quadraticdiscriminantanalysis#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cb3a4d-ea17-4b26-a0d2-62f7e1bb9ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to display the results\n",
    "results = pd.DataFrame({\n",
    "    'Classifier': names,\n",
    "    'Training Accuracy': scores_train,\n",
    "    'Testing Accuracy': scores_test\n",
    "})\n",
    "\n",
    "# Display the results as a table\n",
    "print(\"\\nClassifier Accuracy Comparison:\")\n",
    "print(results.sort_values(by='Testing Accuracy', ascending=False))\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "results_sorted = results.sort_values(by='Testing Accuracy', ascending=False)\n",
    "x = np.arange(len(names))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, results_sorted['Training Accuracy'], width, label='Training Accuracy')\n",
    "plt.bar(x + width/2, results_sorted['Testing Accuracy'], width, label='Testing Accuracy')\n",
    "\n",
    "plt.xlabel('Classifier')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Classifier Performance Comparison')\n",
    "plt.xticks(x, results_sorted['Classifier'], rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find the best classifier\n",
    "best_idx = np.argmax(scores_test)\n",
    "print(f\"\\nBest classifier: {names[best_idx]} with test accuracy: {scores_test[best_idx]:.2%}\")\n",
    "\n",
    "# Let's see the confusion matrix for the best classifier\n",
    "best_clf = Pipeline([('preproc', StandardScaler()), ('classifier', classifiers[best_idx])])\n",
    "best_clf.fit(features_train, labels_train)\n",
    "print(\"\\nConfusion Matrix for the Best Classifier:\")\n",
    "ConfusionMatrixDisplay.from_estimator(best_clf, features_test, labels_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3815b3fc-c2b8-4754-8788-5bb5c1f03643",
   "metadata": {},
   "source": [
    "Let's print the results as a table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db1e757-07a5-4f37-9fc7-5fbe661b3976",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(index=names)\n",
    "res['Train'] = scores_train  # Use correct column name from the start\n",
    "res['Test'] = scores_test    # Use correct column name from the start\n",
    "res.index.name = \"Classifier accuracy\"\n",
    "pd.options.display.float_format = '{:.2f}'.format  # Format to 2 decimal places\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3005c75-3487-4908-9d59-2a10c632145b",
   "metadata": {},
   "source": [
    "You can see that the calculations are very fast and that Logistic Regression and Neural Network show the best result for the test DataSet.\n",
    "\n",
    "Let's compare the results on a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d2e0ea-0966-4c76-b824-53bec4761899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the comparison of training and testing accuracies\n",
    "x = np.arange(len(names))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))  # Create a larger figure for better readability\n",
    "rects1 = ax.bar(x - width/2, scores_train, width, label='Train')\n",
    "rects2 = ax.bar(x + width/2, scores_test, width, label='Test')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy of Classifiers')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(names, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "\n",
    "# Add a grid for easier comparison\n",
    "ax.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add value annotations on top of bars\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.2f}',\n",
    "                   xy=(rect.get_x() + rect.get_width()/2, height),\n",
    "                   xytext=(0, 3),  # 3 points vertical offset\n",
    "                   textcoords=\"offset points\",\n",
    "                   ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7196494c-ade5-4834-a473-15b68dae8f14",
   "metadata": {},
   "source": [
    "# Building and fitting Convolutional Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4c08b6-cbdf-45c8-bbe2-a515a5becc6b",
   "metadata": {},
   "source": [
    "## Required libraries import\n",
    "\n",
    "We will use Keras library for creating and training our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0027dab1-a06f-4e98-b726-ac747a5aa655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe39c45-140f-43a2-a4bc-1b80e720b8a0",
   "metadata": {},
   "source": [
    "## Data preprocessing and data augmentation\n",
    "\n",
    "What is different about [Convolutional Neural Networks](https://en.wikipedia.org/wiki/Convolutional_neural_network) is that we can submit images directly to the input. However, these images also require pre-processing. \n",
    "\n",
    "In particular, it is necessary to normalize the pixels color, i.e. to normalize them from the range [0, 255) to [0, 1).\n",
    "\n",
    "You also need to change the dimension of the input images because of Keras framework. \n",
    "\n",
    "Image classes should be of numeric type instead of string.\n",
    "\n",
    "The code below makes the necessary transformations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8c032c-77bc-401d-8f74-db46f23ea157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists for training and validation data\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "for feature, label in zip(train_images, train_labels):\n",
    "    x_train.append(feature)\n",
    "    y_train.append(label)\n",
    "\n",
    "for feature, label in zip(val_images, val_labels):\n",
    "    x_val.append(feature)\n",
    "    y_val.append(label)\n",
    "\n",
    "# Normalize the data (pixel values from [0,255] to [0,1])\n",
    "x_train = np.array(x_train) / 255\n",
    "x_val = np.array(x_val) / 255\n",
    "\n",
    "# Reshape images to add channel dimension for CNN input\n",
    "# (samples, height, width, channels)\n",
    "x_train = x_train.reshape(-1, IMM_SIZE, IMM_SIZE, 1)\n",
    "x_val = x_val.reshape(-1, IMM_SIZE, IMM_SIZE, 1)\n",
    "\n",
    "# Create a mapping from string labels to numeric indices\n",
    "lab = {}\n",
    "for i, l in enumerate(sorted(set(y_train))):\n",
    "    lab[l] = i\n",
    "\n",
    "# Convert string labels to numeric indices\n",
    "y_train = np.array([lab[l] for l in y_train])\n",
    "y_val = np.array([lab[l] for l in y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e5a077-24f6-4d2e-a3c2-0f37a00cde8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of the input DataSet:\", x_train.shape)\n",
    "print(\"Shape of the output DataSet:\", y_train.shape)\n",
    "print(\"Dictionary of classes:\", lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2235d951-f292-47a0-b074-f255bb68338d",
   "metadata": {},
   "source": [
    "## Data augmentation on the training data\n",
    "\n",
    "We should perform data augmentation to fit our model better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a749e19c-c48f-4f9d-84e7-c9b7d65ceef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range=0.2,  # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally\n",
    "        height_shift_range=0.1,  # randomly shift images vertically\n",
    "        horizontal_flip=True,  # randomly flip images horizontally\n",
    "        vertical_flip=False,  # don't flip images vertically\n",
    "        brightness_range=[0.8, 1.2],  # randomly adjust brightness\n",
    "        fill_mode='nearest')  # strategy for filling points outside boundaries\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa10a7f-9019-4bdd-9f20-7cc4614a2020",
   "metadata": {},
   "source": [
    "## Model defining\n",
    "\n",
    "Let’s define a simple CNN model with 3 Convolutional layers followed by max-pooling layers. A dropout layer is added after the 3rd maxpool operation to avoid overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5e2d47-13a7-49d4-9bb4-55b173043637",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "\n",
    "# Define model using the recommended approach\n",
    "model = Sequential([\n",
    "    # Input layer explicitly defined\n",
    "    Input(shape=(IMM_SIZE, IMM_SIZE, 1)),\n",
    "    \n",
    "    # First convolutional block\n",
    "    Conv2D(32, 1, padding=\"same\", activation=\"relu\"),\n",
    "    MaxPool2D(),\n",
    "    \n",
    "    # Second convolutional block\n",
    "    Conv2D(32, 1, padding=\"same\", activation=\"relu\"),\n",
    "    MaxPool2D(),\n",
    "    \n",
    "    # Third convolutional block\n",
    "    Conv2D(64, 1, padding=\"same\", activation=\"relu\"),\n",
    "    MaxPool2D(),\n",
    "    Dropout(0.4),\n",
    "    \n",
    "    # Fully connected layers\n",
    "    Flatten(),\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    Dense(3, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5892e54-35ff-49e2-9502-45f79278fa9b",
   "metadata": {},
   "source": [
    "Let’s compile the model now using Adam as our optimizer and SparseCategoricalCrossentropy as the loss function. We are using a lower learning rate of 0.000001 for a smoother curve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442bfb61-ff4f-42d4-aca8-440ce2b9af55",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=0.000001)\n",
    "\n",
    "# Compile the model with appropriate loss function\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65acec6-199d-4e3b-866e-f474de64b19f",
   "metadata": {},
   "source": [
    "Now, let’s train our model for **2000** epochs.\n",
    "Admittedly, the fitting process is very slow. Therefore, we saved the fitted model to a file.\n",
    "To save time, we will upload the fitted model.\n",
    "If you would like, you can change the parameter **fitting to True** in order to refit the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f332d592-1fd3-458b-aa68-d1509df02bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training parameters\n",
    "fitting = False  # Change to True if you want to train the model\n",
    "fitting_save = True  # Whether to save the trained model (when fitting=True)\n",
    "epochs = 2000  # Number of epochs to train for\n",
    "\n",
    "# Import necessary libraries for model loading/saving\n",
    "import pickle\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Ensure tf version is printed to help with debugging\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "if fitting:\n",
    "    print(f\"Training model for {epochs} epochs...\")\n",
    "    \n",
    "    # Add callbacks for better training\n",
    "    callbacks = [\n",
    "        # Save best model based on validation accuracy\n",
    "        ModelCheckpoint(\n",
    "            \"best_model.h5\", \n",
    "            monitor=\"val_accuracy\",\n",
    "            save_best_only=True,\n",
    "            mode=\"max\"\n",
    "        ),\n",
    "        # Early stopping to prevent overfitting\n",
    "        EarlyStopping(\n",
    "            monitor=\"val_accuracy\",\n",
    "            patience=50,  # Generous patience for long training\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        # Reduce learning rate when training plateaus\n",
    "        ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\",\n",
    "            factor=0.5,\n",
    "            patience=20,\n",
    "            min_lr=1e-7\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Train the model with data augmentation\n",
    "    history = model.fit(\n",
    "        datagen.flow(x_train, y_train, batch_size=32),\n",
    "        epochs=epochs,\n",
    "        validation_data=(x_val, y_val),\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    if fitting_save:\n",
    "        print(\"Saving model...\")\n",
    "        \n",
    "        # First, the modern recommended way - save complete model\n",
    "        model.save(\"covid_model_complete\")\n",
    "        \n",
    "        # Also save as weights + architecture for compatibility\n",
    "        model.save_weights(\"covid_model_weights.h5\")\n",
    "        \n",
    "        # Save model architecture as JSON\n",
    "        with open(\"covid_model_architecture.json\", \"w\") as f:\n",
    "            f.write(model.to_json())\n",
    "            \n",
    "        # Save training history and class mapping\n",
    "        with open('training_history.pickle', 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "        with open('class_mapping.pickle', 'wb') as f:\n",
    "            pickle.dump(lab, f)\n",
    "            \n",
    "        print(\"Model saved successfully\")\n",
    "        \n",
    "else:\n",
    "    print(\"Using pretrained model...\")\n",
    "    \n",
    "    # If we're not training, we'll always rebuild the model\n",
    "    # This ensures compatibility and avoids version issues\n",
    "    \n",
    "    # First, check if we have history files to load\n",
    "    if os.path.exists('history.pickle'):\n",
    "        with open('history.pickle', 'rb') as f:\n",
    "            history = pickle.load(f)\n",
    "        print(\"Loaded training history\")\n",
    "    else:\n",
    "        print(\"No training history found\")\n",
    "    \n",
    "    # Recreate the model architecture - this is our fallback approach\n",
    "    print(\"Creating model with pretrained architecture...\")\n",
    "    \n",
    "    # Model is already defined earlier in the notebook\n",
    "    # Compile with slightly higher learning rate since we're not training from scratch\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Try to load weights if they exist\n",
    "    try:\n",
    "        if os.path.exists(\"model.h5\"):\n",
    "            model.load_weights(\"model.h5\")\n",
    "            print(\"✅ Successfully loaded pretrained weights\")\n",
    "        else:\n",
    "            print(\"⚠️ Could not find pretrained weights\")\n",
    "            print(\"You may want to set fitting=True to train the model from scratch\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error loading weights: {e}\")\n",
    "        print(\"You may need to set fitting=True to train the model from scratch\")\n",
    "\n",
    "# Print quick summary of model status\n",
    "print(\"\\nModel summary:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa41fa0-0264-4608-aefc-bbbddf7ca30e",
   "metadata": {},
   "source": [
    "## Results evaluation\n",
    "\n",
    "We will plot our training and validation accuracy along with the training and validation loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a884147-a0e9-4d27-904f-3404c5581205",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history['accuracy']\n",
    "val_acc = history['val_accuracy']\n",
    "loss = history['loss']\n",
    "val_loss = history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b5375b-f8dc-426a-ac3a-155122ed1bea",
   "metadata": {},
   "source": [
    "Let’s see what the curve looks like.\n",
    "You can see that the accuracy of the training and validation sets is the same. The loss function of validation and training sets is stable. It means that our CNN is fitted well and can be used for classification.\n",
    "\n",
    "We can print out the classification report to see the precision and accuracy using [model.predict_classes()]() and [classification_report()]().\n",
    "\n",
    "Also we can create a confusion matrix. Unfortunately, Keras framework does not have plot_confusion_matrix() function. Therefore, we have to create it using Pandas and [Seaborn.heatmap()]()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6aa05a-d3c7-4265-9dcd-b85d7291078b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model predictions\n",
    "predictions_prob = model.predict(x_val)  # This returns class probabilities\n",
    "predictions = np.argmax(predictions_prob, axis=1)  # Get the class with highest probability\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, predictions, target_names=list(lab.keys())))\n",
    "\n",
    "# Create and display confusion matrix as a table\n",
    "cm = pd.DataFrame(confusion_matrix(y_val, predictions))\n",
    "# Convert numeric indices back to class names\n",
    "class_mapping = {v: k for k, v in lab.items()}  # Reverse mapping from index to class name\n",
    "cm.index = [f\"Predicted {class_mapping[i]}\" for i in range(len(lab))]\n",
    "cm.columns = [f\"True {class_mapping[i]}\" for i in range(len(lab))]\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Create a heatmap visualization of the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_matrix(y_val, predictions), annot=True, fmt='d',\n",
    "            xticklabels=list(lab.keys()), yticklabels=list(lab.keys()),\n",
    "            cmap='Blues', linewidths=1, linecolor='black')\n",
    "plt.xlabel(\"True labels\")\n",
    "plt.ylabel(\"Predicted labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display overall accuracy\n",
    "accuracy = np.mean(predictions == y_val)\n",
    "print(f\"\\nOverall Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "# Display examples of misclassified images\n",
    "misclassified = np.where(predictions != y_val)[0]\n",
    "if len(misclassified) > 0:\n",
    "    print(f\"\\nShowing {min(4, len(misclassified))} misclassified examples:\")\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    for i, idx in enumerate(misclassified[:4]):\n",
    "        plt.subplot(1, 4, i+1)\n",
    "        plt.imshow(x_val[idx].reshape(IMM_SIZE, IMM_SIZE), cmap='gray')\n",
    "        plt.title(f\"True: {class_mapping[y_val[idx]]}\\nPred: {class_mapping[predictions[idx]]}\")\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\nNo misclassified examples found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793bafcb-3687-436f-a0e1-a328c8346aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = model.predict(x_train)  # Get probabilities\n",
    "predictions_train_classes = np.argmax(predictions_train, axis=1)  # Convert to class indices\n",
    "scores_train = np.mean(predictions_train_classes == y_train)  # Calculate accuracy\n",
    "\n",
    "# For validation/test set\n",
    "predictions_val = model.predict(x_val)  # Get probabilities\n",
    "predictions_val_classes = np.argmax(predictions_val, axis=1)  # Convert to class indices\n",
    "scores_test = np.mean(predictions_val_classes == y_val)  # Calculate accuracy\n",
    "\n",
    "print('Training DataSet accuracy: {: .1%}'.format(scores_train), 'Test DataSet accuracy: {: .1%}'.format(scores_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79c016f-06a7-4621-ab16-78e62f129ef1",
   "metadata": {},
   "source": [
    "As you can see, the CNN shows better results than classical models. However, fitting takes much longer.\n",
    "\n",
    "And now, on your own, try to create a function that will establish a diagnosis based on the CNN. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29057d71-b319-4db9-9e7a-5f1f91d7225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnosis(file):\n",
    "    \"\"\"\n",
    "    Diagnose an X-ray image using the trained CNN model.\n",
    "    \n",
    "    Parameters:\n",
    "    file (str): Path to the image file\n",
    "    \n",
    "    Returns:\n",
    "    str: The diagnosis (Covid, Normal, or Viral Pneumonia)\n",
    "    \"\"\"\n",
    "    # Download image\n",
    "    image = mh.imread(file)\n",
    "    \n",
    "    # Prepare image to classification\n",
    "    if len(image.shape) > 2:\n",
    "        image = mh.resize_to(image, [IMM_SIZE, IMM_SIZE, image.shape[2]])\n",
    "        # Remove alpha channel if present\n",
    "        image = mh.colors.rgb2grey(image[:,:,:3], dtype=np.uint8)\n",
    "    else:\n",
    "        image = mh.resize_to(image, [IMM_SIZE, IMM_SIZE])\n",
    "        \n",
    "    # Show image\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title('Input X-ray image')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Load model\n",
    "    # Note: We assume the model is already loaded as 'model' \n",
    "    # and the class mapping dictionary 'lab' is available from previous cells\n",
    "    \n",
    "    # Create reverse mapping from index to class name\n",
    "    class_mapping = {v: k for k, v in lab.items()}\n",
    "    \n",
    "    # Normalize the data\n",
    "    image_normalized = image / 255.0\n",
    "    \n",
    "    # Reshape input images\n",
    "    image_reshaped = image_normalized.reshape(1, IMM_SIZE, IMM_SIZE, 1)\n",
    "    \n",
    "    # Predict the diagnosis\n",
    "    prediction = model.predict(image_reshaped)\n",
    "    prediction_class = np.argmax(prediction, axis=1)[0]\n",
    "    \n",
    "    # Get prediction probabilities for each class\n",
    "    probabilities = prediction[0]\n",
    "    \n",
    "    # Find the name of the diagnosis\n",
    "    diag = class_mapping[prediction_class]\n",
    "    \n",
    "    # Print detailed results\n",
    "    print(f\"Diagnosis: {diag}\")\n",
    "    print(\"\\nProbabilities:\")\n",
    "    for i, (class_name, prob) in enumerate(zip(lab.keys(), probabilities)):\n",
    "        print(f\"{class_name}: {prob:.2%}\")\n",
    "        \n",
    "    # Visualize confidence levels\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(lab.keys(), probabilities, color='skyblue')\n",
    "    plt.xlabel('Diagnosis')\n",
    "    plt.ylabel('Confidence')\n",
    "    plt.title('Prediction Confidence')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.axhline(y=0.5, color='r', linestyle='--', alpha=0.5)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    for i, v in enumerate(probabilities):\n",
    "        plt.text(i, v + 0.02, f\"{v:.2%}\", ha='center')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0f285b-0940-4979-88ff-5bc42669df00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Diagnosis is:\", diagnosis(\"Covid19-dataset/test/Covid/0120.jpg\"))\n",
    "print (\"Diagnosis is:\", diagnosis(\"Covid19-dataset/test/Normal/0105.jpeg\"))\n",
    "print (\"Diagnosis is:\", diagnosis(\"Covid19-dataset/test/Viral Pneumonia/0111.jpeg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5babf4-d639-442d-8aa3-0ec4d5d1281a",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "This lab has revealed for us how to create an expert system that allows us to obtain diagnosis based on X-Rays images, using different classificators. This principles can be used for any type of X-Rays, not only for COVID diagnostics.\n",
    "\n",
    "During this laboratory work, we have explored images downloading and transforming. We have learned how to extract features of images and build/fit/test/compare sets of classificators. Also we got to know how to create and fit Convolutional Neural Networks. We have compared accuracy of different classificators. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d8c7b9-26c9-4672-8bbf-0641cf016c45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
